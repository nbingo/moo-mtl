{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce83b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import pickle\n",
    "import itertools\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from fvcore.common.config import CfgNode\n",
    "from rtb import log_every_n_seconds, log_first_n, setup_logger\n",
    "\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7020ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_objective.main import get_config, evaluate, method_from_name, main\n",
    "from multi_objective import utils, defaults\n",
    "from multi_objective.objectives import from_name\n",
    "\n",
    "from multi_objective.methods import HypernetMethod, ParetoMTLMethod, SingleTaskMethod, COSMOSMethod, MGDAMethod, UniformScalingMethod\n",
    "from multi_objective.scores import from_objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71f0c4",
   "metadata": {},
   "source": [
    "Prepare submitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e691272",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder=\"tmp/submitit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3604f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.update_parameters(timeout_min=20, slurm_partition=\"testdlc_gpu-rtx2080\", name='debug', gpus_per_node=1)\n",
    "executor.update_parameters(slurm_array_parallelism=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f8a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27ed6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalu(method_name, cfg, checkpoint_dir, tag='eval', last_only=True, splits=['val']):\n",
    "    cfg.freeze()\n",
    "    # create the experiment folders\n",
    "    logdir = os.path.join(cfg['logdir'], method_name, cfg['dataset'], utils.get_runname(cfg) + f'_{tag}')\n",
    "    pathlib.Path(logdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger = setup_logger(os.path.join(logdir, 'exp.log'), name=__name__)\n",
    "    logger.info(f\"start experiment with settings {cfg}\")\n",
    "\n",
    "    # prepare\n",
    "    utils.set_seed(cfg['seed'])\n",
    "    objectives = from_name(**cfg)\n",
    "    scores = from_objectives(objectives, **cfg)\n",
    "\n",
    "    train_loader, val_loader, test_loader, sampler = utils.loaders_from_name(**cfg)\n",
    "\n",
    "    model = utils.model_from_dataset(**cfg).to(cfg.device)\n",
    "    method = method_from_name(method_name, objectives, model, cfg)\n",
    "\n",
    "    train_results = dict(settings=cfg, num_parameters=utils.num_parameters(method.model_params()))\n",
    "    val_results = dict(settings=cfg, num_parameters=utils.num_parameters(method.model_params()))\n",
    "    test_results = dict(settings=cfg, num_parameters=utils.num_parameters(method.model_params()))\n",
    "    \n",
    "#     task_ids = settings['task_ids'] if method_name == 'single_task' else [0]\n",
    "    task_ids = [0]\n",
    "    for j in task_ids:\n",
    "        checkpoints = pathlib.Path(checkpoint_dir).glob('**/c_*.pth')\n",
    "\n",
    "        train_results[f\"start_{j}\"] = {}\n",
    "        val_results[f\"start_{j}\"] = {}\n",
    "        test_results[f\"start_{j}\"] = {}\n",
    "\n",
    "        if last_only:\n",
    "            # Eval only last checkpoint\n",
    "            checkpoints = [list(sorted(checkpoints))[-1]]\n",
    "\n",
    "        for c in sorted(checkpoints):\n",
    "            print(\"checkpoint\", c)\n",
    "            _, e = c.stem.replace('c_', '').split('-')\n",
    "\n",
    "            j = int(j)\n",
    "            e = int(e)\n",
    "            \n",
    "            method.model.load_state_dict(torch.load(c))\n",
    "\n",
    "            # Validation results\n",
    "            if 'val' in splits:\n",
    "                val_results = evaluate(j, e, method, scores, val_loader,\n",
    "                        split='val',\n",
    "                        result_dict=val_results,\n",
    "                        logdir=logdir,\n",
    "                        train_time=0,\n",
    "                        cfg=cfg,\n",
    "                        logger=logger,)\n",
    "\n",
    "            # Test results\n",
    "            if 'test' in splits:\n",
    "                test_results = evaluate(j, e, method, scores, test_loader,\n",
    "                        split='test',\n",
    "                        result_dict=test_results,\n",
    "                        logdir=logdir,\n",
    "                        train_time=0,\n",
    "                        cfg=cfg,\n",
    "                        logger=logger,)\n",
    "\n",
    "            # Train results\n",
    "            if 'train' in splits:\n",
    "                train_results = evaluate(j, e, method, scores, train_loader,\n",
    "                        split='train',\n",
    "                        result_dict=train_results,\n",
    "                        logdir=logdir,\n",
    "                        train_time=0,\n",
    "                        cfg=cfg,\n",
    "                        logger=logger,)\n",
    "    result = {}\n",
    "    if 'val' in splits:\n",
    "        result['val'] = val_results['start_0'][f'epoch_{e}']\n",
    "    if 'train' in splits:\n",
    "        result['train'] = train_results['start_0'][f'epoch_{e}']\n",
    "    if 'test' in splits:\n",
    "        result['test'] = test_results['start_0'][f'epoch_{e}']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe2888",
   "metadata": {},
   "source": [
    "Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6158e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs(method, dataset, root='results'):\n",
    "    path = pathlib.Path(os.path.join(root, method, dataset))\n",
    "    return list(sorted(path.glob('*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a09eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('results/mgda/cityscapes/5006462_full_approx'),\n",
       " PosixPath('results/mgda/cityscapes/5006467_full_no_approx'),\n",
       " PosixPath('results/mgda/cityscapes/5607578_lossfix'),\n",
       " PosixPath('results/mgda/cityscapes/5744156_eval'),\n",
       " PosixPath('results/mgda/cityscapes/5744159_eval'),\n",
       " PosixPath('results/mgda/cityscapes/5793458_eval')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dirs('mgda', 'cityscapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64834ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbc8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'mgda'\n",
    "dataset = 'cityscapes'\n",
    "cfg = get_config(f'configs/{dataset}.yaml')\n",
    "checkpoint_dir = get_dirs(method, dataset)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc9915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84e217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47829892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fb9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = executor.submit(evalu, method, cfg, checkpoint_dir, tag='eval', last_only=True, splits=['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b2dd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'loss': {'center_ray': [0.27116543878065913,\n",
       "    2.7455966441254867,\n",
       "    29.06497473465769]},\n",
       "  'metrics': {'center_ray': [0.4946948167252065,\n",
       "    2.7455966441254867,\n",
       "    29.06497473465769]},\n",
       "  'training_time_so_far': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52bc5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb4847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a4865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c4ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4419c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a85378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23e383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b4367de",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder=\"tmp/submitit\")\n",
    "executor.update_parameters(timeout_min=20, slurm_partition=\"ml_gpu-rtx2080\", name='debug', gpus_per_node=8)\n",
    "executor.update_parameters(slurm_array_parallelism=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c0433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_distributed(world_size, method, cfg, tag):\n",
    "    mp.spawn(main,\n",
    "            args=(world_size, method, cfg, tag),\n",
    "            nprocs=world_size,\n",
    "            join=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202d8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4792cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'cosmos'\n",
    "dataset = 'cityscapes'\n",
    "cfg = get_config(f'configs/{dataset}.yaml')\n",
    "tag = 'test'\n",
    "world_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc1be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c237c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = executor.submit(run_distributed, world_size, method, cfg, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "108f5169",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedJobError",
     "evalue": "Job (task=0) failed during processing with trace:\n----------------------\nTraceback (most recent call last):\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/submitit/core/submission.py\", line 53, in process_job\n    result = delayed.result()\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/submitit/core/utils.py\", line 128, in result\n    self._result = self.function(*self.args, **self.kwargs)\n  File \"<ipython-input-25-97c057ba50a8>\", line 2, in run_distributed\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 199, in spawn\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 157, in start_processes\n    while not context.join():\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 118, in join\n    raise Exception(msg)\nException: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 19, in _wrap\n    fn(i, *args)\n  File \"/home/ruchtem/dev/moo/multi_objective/main.py\", line 244, in main\n    assert not math.isnan(loss) and not math.isnan(sim)\nAssertionError\n\n\n----------------------\nYou can check full logs with 'job.stderr(0)' and 'job.stdout(0)'or at paths:\n  - /home/ruchtem/dev/moo/tmp/submitit/5616032_0_log.err\n  - /home/ruchtem/dev/moo/tmp/submitit/5616032_0_log.out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedJobError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-97f4f20faa6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/venvs/base/lib/python3.8/site-packages/submitit/core/core.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You should use `results()` if your job has subtasks.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/venvs/base/lib/python3.8/site-packages/submitit/core/core.py\u001b[0m in \u001b[0;36mresults\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjob_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown job exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mjob_exception\u001b[0m  \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedJobError\u001b[0m: Job (task=0) failed during processing with trace:\n----------------------\nTraceback (most recent call last):\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/submitit/core/submission.py\", line 53, in process_job\n    result = delayed.result()\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/submitit/core/utils.py\", line 128, in result\n    self._result = self.function(*self.args, **self.kwargs)\n  File \"<ipython-input-25-97c057ba50a8>\", line 2, in run_distributed\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 199, in spawn\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 157, in start_processes\n    while not context.join():\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 118, in join\n    raise Exception(msg)\nException: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/ruchtem/dev/venvs/base/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 19, in _wrap\n    fn(i, *args)\n  File \"/home/ruchtem/dev/moo/multi_objective/main.py\", line 244, in main\n    assert not math.isnan(loss) and not math.isnan(sim)\nAssertionError\n\n\n----------------------\nYou can check full logs with 'job.stderr(0)' and 'job.stdout(0)'or at paths:\n  - /home/ruchtem/dev/moo/tmp/submitit/5616032_0_log.err\n  - /home/ruchtem/dev/moo/tmp/submitit/5616032_0_log.out"
     ]
    }
   ],
   "source": [
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e42cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
