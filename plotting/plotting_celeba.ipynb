{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586e272b-3b26-4bb1-994d-284595e876f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pymoo.factory import get_performance_indicator\n",
    "\n",
    "#\n",
    "# Helper functions\n",
    "#\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)\n",
    "\n",
    "\n",
    "def get_early_stop(epoch_data, key='hv'):\n",
    "    assert key in ['hv', 'score', 'last']\n",
    "    if key == 'hv':\n",
    "        best_hv = 0\n",
    "        best_idx = None\n",
    "        for e in natural_sort(epoch_data.keys()):\n",
    "            if 'epoch' in e and 'loss' in epoch_data[e]:\n",
    "                hv = epoch_data[e]['loss']['hv']\n",
    "                if hv > best_hv:\n",
    "                    best_hv = hv\n",
    "                    best_idx = e\n",
    "        return best_idx\n",
    "    elif key == 'score':\n",
    "        min_score = 1e15\n",
    "        min_epoch = -1\n",
    "        for e in natural_sort(epoch_data.keys()):\n",
    "            if 'scores' in epoch_data[e]:\n",
    "                s = epoch_data[e]['scores'][0]\n",
    "                s = s[epoch_data[e]['task']]\n",
    "\n",
    "                if s < min_score:\n",
    "                    min_score = s\n",
    "                    min_epoch = e\n",
    "\n",
    "        return int(min_epoch.replace('epoch_', ''))\n",
    "    elif key == 'last':\n",
    "        last_epoch = natural_sort(epoch_data.keys())[-1]\n",
    "        return int(last_epoch.replace('epoch_', ''))\n",
    "\n",
    "\n",
    "def load_files(paths):\n",
    "    contents = []\n",
    "    for p in paths:\n",
    "        with p.open(mode='r') as json_file:\n",
    "            contents.append(json.load(json_file))\n",
    "    return contents\n",
    "\n",
    "\n",
    "def mean_and_std(values):\n",
    "    return (\n",
    "        np.array(values).mean(axis=0).tolist(),\n",
    "        np.array(values).std(axis=0).tolist()\n",
    "    )\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "\n",
    "def get_hv(sol):\n",
    "    hv = get_performance_indicator(\"hv\", ref_point=np.array([1, 1]))\n",
    "    return hv.do(np.array(sol))\n",
    "\n",
    "\n",
    "def adjust_lightness(color, amount=0.5):\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], max(0, min(1, amount * c[1])), c[2])\n",
    "\n",
    "\n",
    "#\n",
    "# Plotting params\n",
    "#\n",
    "font_size = 12\n",
    "figsize=(14, 3.5)\n",
    "\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "plt.tight_layout()\n",
    "\n",
    "markers = {\n",
    "    'mgda': 'x', \n",
    "    'uniform': '^',\n",
    "    # 'phn': '.', \n",
    "    'cosmos': 'd', \n",
    "    # 'phn_orig': '.', \n",
    "    'cosmos_orig': 'd', \n",
    "    'pmtl': '*',\n",
    "    'linear_scalarization': '.',\n",
    "    'calibrated_linear_scalarization': '.',\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    'single_task': '#1f77b4', \n",
    "    # 'mgda': '#ff7f0e', \n",
    "    # 'phn_orig': '#800000',\n",
    "    # 'phn': '#2ca02c',\n",
    "    'cosmos_orig': '#f58231',\n",
    "    'linear_scalarization': '#800000',\n",
    "    'calibrated_linear_scalarization': '#2ca02c',\n",
    "    # 'cosmos': '#d62728',\n",
    "    # 'pmtl': '#9467bd', \n",
    "    # 'uniform': '#f032e6', \n",
    "}\n",
    "\n",
    "titles = {\n",
    "    'multi_mnist': \"Multi-MNIST\", \n",
    "    'multi_fashion': 'Multi-Fashion',\n",
    "    'multi_fashion_mnist': 'Multi-Fashion+MNIST',\n",
    "    'celeba': 'Celeba',\n",
    "}\n",
    "\n",
    "ax_lables_loss = {\n",
    "    'multi_mnist': ('Cross-Entropy Loss Task TL', 'Cross-Entropy Loss Task BR'), \n",
    "    'multi_fashion': ('Cross-Entropy Loss Task TL', 'Cross-Entropy Loss Task BR'), \n",
    "    'multi_fashion_mnist': ('Cross-Entropy Loss Task TL', 'Cross-Entropy Loss Task BR'), \n",
    "    'celeba': ('Binary Cross-Entroy Loss Task 16', 'Binary Cross-Entroy Loss Task 22')\n",
    "}\n",
    "\n",
    "ax_lables_mcr = {\n",
    "    'multi_mnist': ('Misclassification Rate Task TL', 'Misclassification Rate Task BR'), \n",
    "    'multi_fashion': ('Misclassification Rate Task TL', 'Misclassification Rate Task BR'), \n",
    "    'multi_fashion_mnist': ('Misclassification Rate Task TL', 'Misclassification Rate Task BR'), \n",
    "    'celeba': ('Misclassification Rate Task 16', 'Misclassification Rate Task 22')\n",
    "}\n",
    "\n",
    "method_names = {\n",
    "    'single_task': 'Single Task', \n",
    "    'phn': 'PHN*',\n",
    "    'phn_orig': 'PHN',\n",
    "    'cosmos_orig': 'COSMOS',\n",
    "    'cosmos': 'COSMOS*',\n",
    "    'pmtl': 'PMTL', \n",
    "    'uniform': 'Uniform',\n",
    "    'mgda': 'MGDA',\n",
    "    'linear_scalarization': 'Linear Scalarization',\n",
    "    'calibrated_linear_scalarization': 'Calibrated Linear Scalarization'\n",
    "}\n",
    "\n",
    "limits_loss = {\n",
    "    # dataset: [left, right, bottom, top]\n",
    "    'multi_mnist': [.4, .4], \n",
    "    'multi_fashion': [.55, .55], \n",
    "    'multi_fashion_mnist': [.55, .55],\n",
    "    'celeba': [.25, .25]\n",
    "}\n",
    "\n",
    "limits_mcr = {\n",
    "    # dataset: [left, bottom]\n",
    "    'multi_mnist': [.12, .12], \n",
    "    'multi_fashion': [.20, .20,], \n",
    "    'multi_fashion_mnist': [.3, .3],\n",
    "    'celeba': [.14, .14]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62cb6456-fd95-48ea-a504-a20e5bbb9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load the data\n",
    "#\n",
    "\n",
    "def load_data(\n",
    "    dirname='results', \n",
    "    datasets=['celeba'],\n",
    "    methods= ['cosmos_orig', 'single_task', 'linear_scalarization', 'calibrated_linear_scalarization'],\n",
    "    custom_metric=False,\n",
    "    ):\n",
    "\n",
    "    metric = 'metrics' if custom_metric else 'loss'\n",
    "\n",
    "    p = Path(dirname)\n",
    "    results = {}\n",
    "\n",
    "    for dataset in datasets:\n",
    "        results[dataset] = {}\n",
    "        for method in methods:\n",
    "            val_file = list(sorted(p.glob(f'**/{method}/{dataset}/*/val*.json')))\n",
    "            test_file = list(sorted(p.glob(f'**/{method}/{dataset}/*/test*.json')))\n",
    "\n",
    "            if len(val_file) == 0:\n",
    "                continue\n",
    "            assert len(val_file) == len(test_file)\n",
    "\n",
    "            data_val = load_files(val_file)\n",
    "            data_test = load_files(test_file)\n",
    "\n",
    "            test_scores = []\n",
    "            test_hv = []\n",
    "            training_time = []\n",
    "\n",
    "            if method == 'single_task':\n",
    "                for (val_run_1, val_run_2), (test_run_1, test_run_2) in zip(pairwise(data_val), pairwise(data_test)):\n",
    "                    e1 = get_early_stop(val_run_1)\n",
    "                    e2 = get_early_stop(val_run_2)\n",
    "                    r1 = test_run_1[e1]\n",
    "                    r2 = test_run_2[e2]\n",
    "\n",
    "                    sol = [r1[metric]['center_ray'][0], r2[metric]['center_ray'][1]]\n",
    "                    test_scores.append(sol)\n",
    "                    test_hv.append(get_hv(sol))\n",
    "                    training_time.append(r1['training_time_so_far'] + r2['training_time_so_far'])\n",
    "\n",
    "                    test_run = test_run_1\n",
    "            else:\n",
    "                for val_run, test_run in zip(data_val, data_test):\n",
    "                    e = get_early_stop(val_run)\n",
    "                    r = test_run[e]\n",
    "                    test_scores.append(r[metric]['pareto_front'] if 'pareto_front' in r[metric] else r[metric]['center_ray'])\n",
    "                    test_hv.append(r[metric]['hv'])\n",
    "                    training_time.append(r['training_time_so_far'])\n",
    "\n",
    "            results[dataset][method] = {\n",
    "                'test_scores': mean_and_std(test_scores),\n",
    "                'test_hv': mean_and_std(test_hv),\n",
    "                'train_time': mean_and_std(training_time),\n",
    "                'num_parameters': test_run['num_parameters'],\n",
    "            }\n",
    "        print(f'loaded data for {dataset}')\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea151732-ee3a-4162-9682-7f131ea7ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_row(results, \n",
    "        datasets=['celeba'],\n",
    "        methods=['single_task', 'cosmos_orig', 'linear_scalarization', 'calibrated_linear_scalarization'],\n",
    "        prefix=''):\n",
    "    assert len(datasets) <= 3\n",
    "    fig, axes = plt.subplots(1, len(datasets), figsize=(4.5*len(datasets), 3.5))\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        if dataset not in results:\n",
    "            continue\n",
    "        ax = axes[j] if isinstance(axes, list) else axes\n",
    "        lower_limit = None\n",
    "        for method in methods:\n",
    "            if method not in results[dataset]:\n",
    "                continue\n",
    "            r = results[dataset][method]\n",
    "            # we take the mean only\n",
    "            s = np.array(r['test_scores'][0])\n",
    "            if s.ndim == 1:\n",
    "                s = np.expand_dims(s, 0)\n",
    "            if method == 'single_task':\n",
    "                s = np.squeeze(s)\n",
    "                ax.axvline(x=s[0], color=colors[method], linestyle='-.')\n",
    "                ax.axhline(y=s[1], color=colors[method], linestyle='-.', label=\"{}\".format(method_names[method]))\n",
    "                lower_limit = s\n",
    "            else:\n",
    "                ax.plot(\n",
    "                    s[:, 0], \n",
    "                    s[:, 1], \n",
    "                    color=colors[method],\n",
    "                    marker=markers[method],\n",
    "                    linestyle='--' if method in ['phn', 'phn_orig', 'cosmos', 'cosmos_orig'] else ' ',\n",
    "                    label=\"{}\".format(method_names[method])\n",
    "                )\n",
    "        lim = limits_loss[dataset] if 'mcr' not in prefix else limits_mcr[dataset]\n",
    "        margin = .05 if 'mcr' not in prefix else 0.005\n",
    "        ax.set_xlim(left=lower_limit[0] - margin, right=lim[0])\n",
    "        ax.set_ylim(bottom=lower_limit[1] - margin, top=lim[1])\n",
    "        ax.set_title(titles[dataset])\n",
    "        ax_lables = ax_lables_loss[dataset] if 'mcr' not in prefix else ax_lables_mcr[dataset]\n",
    "        ax.set_xlabel(ax_lables[0])\n",
    "        if j==0:\n",
    "            ax.set_ylabel(ax_lables[1])\n",
    "\n",
    "        if j==0:\n",
    "            ax.legend(loc='upper right')\n",
    "    plt.subplots_adjust(wspace=.25)\n",
    "    fig.savefig(prefix + '.pdf', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print('success. See', prefix + '.pdf')\n",
    "\n",
    "\n",
    "#\n",
    "# generating the tables\n",
    "#\n",
    "\n",
    "def generate_table(\n",
    "        results, \n",
    "        datasets=['multi_mnist', 'multi_fashion', 'multi_fashion_mnist'], \n",
    "        methods=['single_task', 'uniform', 'mgda', 'pmtl', 'phn', 'phn_orig', 'cosmos', 'cosmos_orig', ],\n",
    "        name='test'\n",
    "    ):\n",
    "    text = f\"\"\"\"\"\"\n",
    "    for method in methods:\n",
    "        if method not in results[datasets[0]]:\n",
    "            continue\n",
    "        text += f\"\"\"\n",
    "{method_names[method]} & #params \"\"\"\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            if dataset not in results:\n",
    "                continue\n",
    "            r = results[dataset][method]\n",
    "            text += f\"\"\" & {r['test_hv'][0]:.4f} $\\pm$ {r['test_hv'][1]:.4f} & {results[dataset]['single_task']['test_hv'][0] - r['test_hv'][0]:.4f}\"\"\"\n",
    "        \n",
    "        text += \"\"\" \\\\\\\\\"\"\"\n",
    "\n",
    "    with open(f'results_{name}.txt', 'w') as f:\n",
    "        f.writelines(text)\n",
    "\n",
    "\n",
    "def generate_table_taskwise(\n",
    "        results, \n",
    "        datasets=['multi_mnist', 'multi_fashion', 'multi_fashion_mnist'], \n",
    "        methods=['single_task', 'uniform', 'mgda', 'pmtl', 'phn', 'phn_orig', 'cosmos', 'cosmos_orig', ],\n",
    "        name='task'\n",
    "    ):\n",
    "    text = f\"\"\"\"\"\"\n",
    "    for method in methods:\n",
    "        if method not in results[datasets[0]]:\n",
    "            continue\n",
    "\n",
    "        text += f\"\"\"\n",
    "{method_names[method]}\"\"\"\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            if dataset not in results:\n",
    "                continue\n",
    "            r = results[dataset][method]\n",
    "            if len(r['test_scores'][0]) == 25:\n",
    "                r['test_scores'] = (\n",
    "                    r['test_scores'][0][12],   # take the middle point of 25 rays\n",
    "                    r['test_scores'][1][12]\n",
    "                )\n",
    "            elif len(r['test_scores'][0]) == 5:\n",
    "                r['test_scores'] = (\n",
    "                    r['test_scores'][0][2],   # take the middle point of 5 rays\n",
    "                    r['test_scores'][1][2]\n",
    "                )\n",
    "\n",
    "            text += f\"\"\" & {r['test_scores'][0][0]:.4f} $\\pm$ {r['test_scores'][1][0]:.4f} & {r['test_scores'][0][1]:.4f} $\\pm$ {r['test_scores'][1][1]:.4f}\"\"\"\n",
    "        \n",
    "        text += \"\"\" \\\\\\\\\"\"\"\n",
    "\n",
    "    with open(f'results_{name}.txt', 'w') as f:\n",
    "        f.writelines(text)\n",
    "\n",
    "\n",
    "def plot_size_ablation(results, datasets=['multi_mnist', 'multi_fashion', 'multi_fashion_mnist'], prefix=''):\n",
    "    fig, axes = plt.subplots(1, len(datasets), figsize=(4.5*len(datasets), 4))\n",
    "    color_lightness = [1.4, 0.8, 0.6, 0.3]\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        ax = axes[j]\n",
    "        handles = []\n",
    "        for i, size_i in enumerate(['0.5', '1', '10', '50']):\n",
    "            lower_limit = None\n",
    "            r = results[i]\n",
    "            if 'single_task' not in r[dataset]:\n",
    "                continue\n",
    "            st = np.array(r[dataset]['single_task']['test_scores'][0])\n",
    "            uf = np.array(r[dataset]['uniform']['test_scores'][0])\n",
    "\n",
    "            st_err = np.array(r[dataset]['single_task']['test_scores'][1])\n",
    "\n",
    "            ax.annotate('', xy=st, xytext=uf, arrowprops={'arrowstyle': '->'})\n",
    "\n",
    "            ax.errorbar(st[0], st[1], xerr=st_err[0], yerr=st_err[1],\n",
    "                ecolor=adjust_lightness(colors['single_task'], amount=color_lightness[i]),\n",
    "                alpha=.3,\n",
    "                capsize=3)\n",
    "\n",
    "            h = ax.plot(\n",
    "                st[0], \n",
    "                st[1], \n",
    "                color=adjust_lightness(colors['single_task'], amount=color_lightness[i]),\n",
    "                marker='+',\n",
    "                label=f\"{method_names['single_task']} (size {size_i})\",\n",
    "                linestyle=' ',\n",
    "            )\n",
    "            handles.append(h[0])\n",
    "\n",
    "            ax.errorbar(uf[0], uf[1], xerr=st_err[0], yerr=st_err[1],\n",
    "                ecolor=adjust_lightness(colors['uniform'], amount=color_lightness[i]),\n",
    "                alpha=.3,\n",
    "                capsize=3)\n",
    "\n",
    "            h = ax.plot(\n",
    "                uf[0], \n",
    "                uf[1], \n",
    "                color=adjust_lightness(colors['uniform'], amount=color_lightness[i]),\n",
    "                marker=markers['uniform'],\n",
    "                label=f\"{method_names['uniform']} (size {size_i})\",\n",
    "                linestyle=' ',\n",
    "            )\n",
    "            handles.append(h[0])\n",
    "\n",
    "            # ax.text(uf[0]+0.002, uf[1]+0.002, f\"size {size_i}\")\n",
    "        ax.set_title(titles[dataset])\n",
    "        ax_lables = ax_lables_loss[dataset] if 'mcr' not in prefix else ax_lables_mcr[dataset]\n",
    "        ax.set_xlabel(ax_lables[0])\n",
    "        if j==0:\n",
    "            ax.set_ylabel(ax_lables[1])\n",
    "            \n",
    "    fig.subplots_adjust(bottom=0.2, wspace=0.25)\n",
    "    axes[1].legend(handles=handles, loc='upper center', \n",
    "             bbox_to_anchor=(0.5, -0.23),fancybox=False, shadow=False, ncol=4)\n",
    "\n",
    "    # axes[0].legend(loc='upper right')\n",
    "\n",
    "    fig.savefig(prefix + 'ablation.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "928b2361-f283-40ff-97c3-b05535e99fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78631/3058411012.py:58: RuntimeWarning: Mean of empty slice.\n",
      "  np.array(values).mean(axis=0).tolist(),\n",
      "/lfs/turing4/0/nomir/mambaforge/envs/moo-mtl/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/lfs/turing4/0/nomir/mambaforge/envs/moo-mtl/lib/python3.9/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/lfs/turing4/0/nomir/mambaforge/envs/moo-mtl/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/lfs/turing4/0/nomir/mambaforge/envs/moo-mtl/lib/python3.9/site-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'test_run' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/lfs/local/0/nomir/moo-mtl/results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msingle_task\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear_scalarization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(dirname, datasets, methods, custom_metric)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 test_hv\u001b[38;5;241m.\u001b[39mappend(r[metric][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhv\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     53\u001b[0m                 training_time\u001b[38;5;241m.\u001b[39mappend(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_time_so_far\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     55\u001b[0m         results[dataset][method] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_and_std(test_scores),\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_hv\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_and_std(test_hv),\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_time\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_and_std(training_time),\n\u001b[0;32m---> 59\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtest_run\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     60\u001b[0m         }\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'test_run' referenced before assignment"
     ]
    }
   ],
   "source": [
    "results = load_data(dirname='/lfs/local/0/nomir/moo-mtl/results', methods=['single_task', 'linear_scalarization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d21da3a-4dc8-48fa-ac86-b1c90d601926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'celeba': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c31276-1f6f-47d6-82f0-71ff0b3f7146",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaselines\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mceleba\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# methods=['single_task', 'cosmos_orig', 'linear_scalarization', 'calibrated_linear_scalarization']\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msingle_task\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear_scalarization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mplot_row\u001b[0;34m(results, datasets, methods, prefix)\u001b[0m\n\u001b[1;32m     34\u001b[0m lim \u001b[38;5;241m=\u001b[39m limits_loss[dataset] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m limits_mcr[dataset]\n\u001b[1;32m     35\u001b[0m margin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.05\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.005\u001b[39m\n\u001b[0;32m---> 36\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlim(left\u001b[38;5;241m=\u001b[39m\u001b[43mlower_limit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m margin, right\u001b[38;5;241m=\u001b[39mlim[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     37\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim(bottom\u001b[38;5;241m=\u001b[39mlower_limit[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m margin, top\u001b[38;5;241m=\u001b[39mlim[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     38\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(titles[dataset])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 324x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_row(results, prefix='baselines', datasets=['celeba'],\n",
    "        # methods=['single_task', 'cosmos_orig', 'linear_scalarization', 'calibrated_linear_scalarization']\n",
    "         methods=['single_task', 'linear_scalarization']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4c9371e-2b26-48af-96fb-230e0cc3907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance([1,2], list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aaa45d0-f5be-45d2-9f6b-df2aea396848",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cosmos_orig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mceleba\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcosmos_orig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cosmos_orig'"
     ]
    }
   ],
   "source": [
    "results['celeba']['cosmos_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f64d9fe-42f1-4916-a9ad-d9b793fd524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.rand(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6256e4a9-01db-4a7d-84a7-d233ea774744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76971038, 0.22571083, 0.89411608, 0.96852937, 0.56946611],\n",
       "       [0.20862544, 0.38963795, 0.73786994, 0.75414663, 0.31087956],\n",
       "       [0.64088266, 0.64160727, 0.40779501, 0.04913566, 0.20243111],\n",
       "       [0.3473308 , 0.71131234, 0.67087917, 0.79356064, 0.94976201]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f30e22b-cc78-4a86-9715-a1389ab3efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20862544 0.38963795 0.73786994 0.75414663 0.31087956]\n",
      "[0.64088266 0.64160727 0.40779501 0.04913566 0.20243111]\n",
      "[0.3473308  0.71131234 0.67087917 0.79356064 0.94976201]\n"
     ]
    }
   ],
   "source": [
    "for r in rand[1:]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073b086-d5e6-431d-89b7-764f3077e4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
